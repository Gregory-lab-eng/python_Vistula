# ğŸ“˜ Profile Picture Validator

## ğŸ¯ Cel projektu

Celem projektu jest stworzenie **API**, ktÃ³re automatycznie waliduje zdjÄ™cia profilowe przesyÅ‚ane przez uÅ¼ytkownikÃ³w.  
Walidacja obejmuje dwa gÅ‚Ã³wne etapy:

1. **Kontrola bezpieczeÅ„stwa zdjÄ™cia (NSFW)**  
   Wykrywanie treÅ›ci niedozwolonych, takich jak nagoÅ›Ä‡, treÅ›ci seksualne lub inne nieodpowiednie elementy.

2. **Weryfikacja, czy zdjÄ™cie przedstawia osobÄ™ z widocznÄ… twarzÄ…**  
   Zapewnienie, Å¼e uÅ¼ytkownik przesyÅ‚a prawidÅ‚owe zdjÄ™cie profilowe.

Docelowo API zwraca prostÄ… odpowiedÅº:

```json
{
  "valid": true,
  "message": "Profile picture accepted"
}
```

## Proces walidacji skÅ‚ada siÄ™ z kilku krokÃ³w:
1. Wczytanie obrazu
ZdjÄ™cie moÅ¼e pochodziÄ‡ z:
uploadu uÅ¼ytkownika,
adresu URL,
pliku lokalnego.

Obraz jest konwertowany do formatu PIL.Image, aby byÅ‚ kompatybilny z modelami.

2. Sprawdzenie bezpieczeÅ„stwa (NSFW)
Do wykrywania treÅ›ci nieodpowiednich uÅ¼ywany jest model:

Falconsai/nsfw_image_detection

Model klasyfikuje obraz jako:
SAFE
UNSAFE

W projekcie logika jest uproszczona:
"NO" â†’ obraz jest bezpieczny
"YES" â†’ obraz narusza zasady i zostaje odrzucony

3. Weryfikacja, czy zdjÄ™cie przedstawia osobÄ™ z twarzÄ…
UÅ¼ywany model
Do sprawdzania, czy zdjÄ™cie przedstawia osobÄ™ z widocznÄ… twarzÄ…, wykorzystywany jest model typu Vision-Language (VQA),
ktÃ³ry potrafi odpowiadaÄ‡ na pytania dotyczÄ…ce obrazu.

Model otrzymuje:
obraz,
pytanie: "Does the image contain a person with a clearly visible face?"
i generuje odpowiedÅº:

"yes" â†’ twarz wykryta
"no" â†’ twarz niewidoczna lub brak osoby
